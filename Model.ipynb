{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, fully_connected, dropout\n",
    "from tflearn.layers.estimator import regression\n",
    "import keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning of Eye Dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images = []\n",
    "labels = []\n",
    "for i in tqdm(os.listdir(\"dataset_B_Eye_Images/Closed/\")):\n",
    "    path = os.path.join(\"dataset_B_Eye_Images/Closed/\", i)\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (24,24))\n",
    "    images.append(np.array(img).reshape(24,24,1))\n",
    "    labels.append(np.array([1,0]))\n",
    "for i in tqdm(os.listdir(\"dataset_B_Eye_Images/Open/\")):\n",
    "    path = os.path.join(\"dataset_B_Eye_Images/Open/\", i)\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (24,24))\n",
    "    images.append(np.array(img).reshape(24,24,1))\n",
    "    labels.append(np.array([0,1]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2)\n",
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = input_data((None, 24, 24, 1))\n",
    "\n",
    "convnet = conv_2d(convnet, 16, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 256, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation=\"relu\")\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation=\"relu\")\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convnet = regression(convnet, learning_rate=1e-9, loss = \"binary_crossentropy\")\n",
    "model = tflearn.DNN(convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\naimi\\Documents\\CAPSTONE\\Capstone_Eyes2\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"Capstone_Eyes1.data-00000-of-00001\"):    \n",
    "    model.fit(X_train, y_train, n_epoch=3, batch_size=8, shuffle=True, show_metric=True, validation_set=(X_test, y_test))\n",
    "    model.save(\"Capstone_Eyes2\")\n",
    "else:\n",
    "    model.load(\"Capstone_Eyes2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n",
      "Blink\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    \n",
    "    for face in faces:\n",
    "        try:\n",
    "            i=0\n",
    "            landmarks = predictor(gray, face)\n",
    "            leftEye = gray[landmarks.part(26).y:landmarks.part(28).y,landmarks.part(22).x:landmarks.part(26).x]\n",
    "            rightEye = gray[landmarks.part(17).y:landmarks.part(28).y,landmarks.part(17).x:landmarks.part(21).x]\n",
    "            leftEye = np.array(cv2.resize(leftEye,(24,24))).reshape(1,24,24,1)\n",
    "            rightEye = np.array(cv2.resize(rightEye,(24,24))).reshape(1,24,24,1)\n",
    "            leftResult = model.predict(leftEye)\n",
    "            rightResult = model.predict(rightEye)\n",
    "            if leftResult.argmax()==0 and leftResult.max()>=0.9:\n",
    "                i+=1\n",
    "                cv2.rectangle(img, (landmarks.part(29).x, landmarks.part(29).y), (landmarks.part(26).x, landmarks.part(26).y), (0,0,255), 5)\n",
    "            elif leftResult.argmax()==1:\n",
    "                cv2.rectangle(img, (landmarks.part(29).x, landmarks.part(29).y), (landmarks.part(26).x, landmarks.part(26).y), (0,255,0), 5)\n",
    "            if rightResult.argmax()==0 and rightResult.max()>=0.9:\n",
    "                i+=1\n",
    "                cv2.rectangle(img, (landmarks.part(29).x, landmarks.part(29).y), (landmarks.part(17).x, landmarks.part(17).y), (0,0,255), 5)\n",
    "            elif rightResult.argmax()==1:\n",
    "                cv2.rectangle(img, (landmarks.part(29).x, landmarks.part(29).y), (landmarks.part(17).x, landmarks.part(17).y), (0,255,0), 5)\n",
    "            if i==2:\n",
    "                print(\"Blink\")\n",
    "                keyboard.press_and_release(\"Space\")\n",
    "               \n",
    "                \n",
    "                \n",
    "        except:\n",
    "            print(Exception)\n",
    " \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
